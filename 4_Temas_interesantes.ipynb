{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAModel:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def train_lda(self, num_topics=10):\n",
    "        # Leer el archivo CSV con las palabras de interés\n",
    "        df_palabras_interesantes = pd.read_csv(self.df)\n",
    "        \n",
    "        # Obtener los documentos como una lista de strings\n",
    "        documentos = df_palabras_interesantes['Palabra'].tolist()\n",
    "        \n",
    "        # Inicializar el vectorizador de conteo\n",
    "        vectorizer = CountVectorizer()\n",
    "        \n",
    "        # Vectorizar los documentos\n",
    "        X = vectorizer.fit_transform(documentos)\n",
    "        \n",
    "        # Inicializar el modelo LDA\n",
    "        lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "        \n",
    "        # Entrenar el modelo LDA\n",
    "        lda_model.fit(X)\n",
    "        \n",
    "        # Obtener las palabras más representativas de cada tópico\n",
    "        topics_words = []\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        for topic_idx, topic in enumerate(lda_model.components_):\n",
    "            topic_words = [feature_names[i] for i in topic.argsort()[:-11:-1]]  # Tomar las 10 palabras más representativas de cada tópico\n",
    "            topics_words.append(topic_words)\n",
    "        \n",
    "        return topics_words\n",
    "    \n",
    "    def visualize_topics(self, topics_words):\n",
    "        # Crear un DataFrame con los tópicos y sus palabras asociadas\n",
    "        df_topics = pd.DataFrame(topics_words, columns=[f\"Tema {i+1}\" for i in range(10)])\n",
    "        \n",
    "        # Crear la tabla visual con matplotlib\n",
    "        plt.figure(figsize=(16, 9))\n",
    "        plt.table(cellText=df_topics.values,\n",
    "                colLabels=df_topics.columns,\n",
    "                cellLoc='center',\n",
    "                loc='center',\n",
    "                colColours=['lightgray']*len(df_topics.columns),\n",
    "                colWidths=[0.1]*len(df_topics.columns))\n",
    "        \n",
    "        # Ocultar ejes\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Mostrar la tabla\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo CSV con las palabras de interés\n",
    "archivo_palabras_interesantes = 'palabras_interesantes.csv'\n",
    "\n",
    "# Crear una instancia de la clase LDAModel\n",
    "lda_modelo = LDAModel(archivo_palabras_interesantes)\n",
    "\n",
    "# Obtener los 5 tópicos con sus palabras asociadas\n",
    "topicos_palabras = lda_modelo.train_lda(num_topics=10)\n",
    "\n",
    "# Visualizar los tópicos y sus palabras asociadas\n",
    "lda_modelo.visualize_topics(topicos_palabras)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
